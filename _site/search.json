{
  "articles": [
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-02-16T11:25:29+01:00"
    },
    {
      "path": "index.html",
      "title": "Machine Learning in R",
      "author": [],
      "contents": "\nEfficient, object-oriented programming on the building blocks of machine learning.\n\n\n\n\n\nEasy interface for scientists and commercial applications.\n\n\n\n\n\nMore than 100 machine learning algorithms.\n\n\n\n\n\nClean OO-design with R6 classes.\n\n\n\n\n\nEasy parallelization with the future package.\n\n\n\n\n\nState-of-the-art optimization algorithms.\n\n\n\n\n\nDataflow programming with pipelines.\n\n\n\n GitHub  Mattermost  Twitter  StackOverflow\n\nQuick Start\nThe mlr3verse meta-package installs mlr3 and some of the most important extension packages:\n\n\ninstall.packages(\"mlr3verse\")\n\n\n\nBasic Example\n\n\nlibrary(mlr3)\n\n# retrieve task\ntask = tsk(\"penguins\")\n\n# load learner and set hyperparameter\nlearner = lrn(\"classif.rpart\", cp = .01)\n\n# automatic resampling\nresampling = rsmp(\"cv\", folds = 3L)\nrr = resample(task, learner, resampling)\n\n# set measure and score\nmeasure = msr(\"classif.acc\")\nrr$score(measure)\n\n\n\nTuning Example\n\n\nlibrary(mlr3tuning)\nlibrary(mlr3tuningspaces)\n\n# retrieve task\ntask = tsk(\"penguins\")\n\n# load learner and set search space\nlearner = lts(lrn(\"classif.rpart\"))\n\n# hyperparameter tuning on the penguins data set\ninstance = tune(\n  method = \"random_search\",\n  task = task,\n  learner = learner,\n  resampling = rsmp(\"cv\", folds = 3),\n  measure = msr(\"classif.acc\"),\n  term_evals = 10,\n  batch_size = 5\n)\n\n# best performing hyperparameter configuration\ninstance$result\n\n\n\nPipelines Example\n\n\nlibrary(mlr3)\nlibrary(mlr3pipelines)\nlibrary(mlr3learners)\n\n# retrieve task\ntask = tsk(\"german_credit\")\n\n# set base and super learner\nbase_learners = list(\n  lrn(\"classif.rpart\", predict_type = \"prob\"),\n  lrn(\"classif.kknn\", predict_type = \"prob\")\n)\nsuper_learner = lrn(\"classif.log_reg\")\n\n# create pipeline and convert to graph learner\ngraph_stack = pipeline_stacking(base_learners, super_learner)\ngraph_learner = as_learner(graph_stack)\n\n# train on german credit task\ngraph_learner$train(task)\n\n\n\nCiting mlr3\nIf you use mlr3, please cite our JOSS article:\n\n@Article{mlr3,\n  title = {{mlr3}: A modern object-oriented machine learning framework in {R}},\n  author = {Michel Lang and Martin Binder and Jakob Richter and Patrick Schratz and Florian Pfisterer and Stefan Coors and Quay Au and Giuseppe Casalicchio and Lars Kotthoff and Bernd Bischl},\n  journal = {Journal of Open Source Software},\n  year = {2019},\n  month = {dec},\n  doi = {10.21105/joss.01903},\n  url = {https://joss.theoj.org/papers/10.21105/joss.01903},\n}\n\n\n\n\n",
      "last_modified": "2022-02-16T11:33:37+01:00"
    },
    {
      "path": "packages.html",
      "title": "Packages",
      "author": [],
      "contents": "\nBasic\nPackage\nStatus\nCRAN\nChecks\nmlr3\n\n\n\nmlr3learners\n\n\n\nmlr3pipelines\n\n\n\nmlr3verse\n\n\n\nOptimization\nPackage\nStatus\nCRAN\nChecks\nbbotk\n\n\n\nmlr3tuning\n\n\n\nmlr3hyperband\n\n\n\nmlr3tuningspaces\n\n\n\nmlr3fselect\n\n\n\nmlr3mbo\n\n\n\nSpatial\nPackage\nStatus\nCRAN\nChecks\nmlr3spatial\n\n\n\nmlr3spatiotempcv\n\n\n\nVisualization\nPackage\nStatus\nCRAN\nChecks\nmlr3viz\n\n\n\nResources\nPackage\nStatus\nCRAN\nChecks\nmlr3book\n\n\n\nmlr3gallery\n\n\n\nMisc\nPackage\nStatus\nCRAN\nChecks\nmlr3batchmark\n\n\n\nmlr3benchmark\n\n\n\nmlr3cluster\n\n\n\nmlr3data\n\n\n\nmlr3db\n\n\n\nmlr3fairness\n\n\n\nmlr3filters\n\n\n\nmlr3measures\n\n\n\nmlr3keras\n\n\n\nmlr3misc\n\n\n\nmlr3oml\n\n\n\nmlr3ordinal\n\n\n\nmlr3proba\n\n\n\nparadox\n\n\n\n\n\n\n",
      "last_modified": "2022-02-16T11:25:30+01:00"
    },
    {
      "path": "resources.html",
      "title": "Resources",
      "author": [],
      "contents": "\nGeneral\nWe started writing a book. This should be the central entry point to the package.\nThe mlr3gallery has some case studies and demonstrates how frequently occurring problems can be solved. It is still in early days so stay tuned for more to come.\nReference manual\nFAQ\nAsk questions on Stackoverflow (tag #mlr3)\nExtension Learners\nRecommended core regression, classification, and survival learners are in mlr3learners\nAll others are in mlr3extralearners\nUse the learner search to get a simple overview\nUse the learner status to see their build status\n\nCheatsheets\nOverview of cheatsheets\nmlr3\nmlr3tuning\nmlr3pipelines\n\nVideos:\nuseR2019 talk on mlr3\nuseR2019 talk on mlr3pipelines and mlr3tuning\nuseR2020 tutorial on mlr3, mlr3tuning and mlr3pipelines\nRecorded talk about mlr3spatiotempcv and mlr3spatial at OpenDataScience Europe Conference 2021 in Wageningen, NL\n\nCourses/Lectures\nThe course Introduction to Machine learning (I2ML) is a free and open flipped classroom course on the basics of machine learning. mlr3 is used in the demos and exercises.\n\nTemplates/Tutorials\nmlr3-learndrake: Shows how to use mlr3 with drake for reproducible ML workflow automation.\n\nList of extension packages\nmlr-outreach contains public talks and slides resources.\nOur blog about mlr and mlr3. (We are not the most frequent bloggers ;) )\nWiki: Contains mainly information for developers.\n\n\n\n",
      "last_modified": "2022-02-16T11:25:31+01:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
